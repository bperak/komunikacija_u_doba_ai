# Index

Ovaj odjeljak sadrži abecedni popis ključnih pojmova korištenih u knjizi, s kratkim definicijama. Definicije su izvučene iz poglavlja 1–8; u tijeku čitanja nalaze se na mjestu prvog spomena.

---

**afektivno računalstvo** — Interdisciplinarno područje istraživanja (engl. *affective computing*) koje se bavi prepoznavanjem, tumačenjem i simulacijom emocija u računalnim sustavima; uključuje analizu izraza lica, glasa i fizioloških signala te primjene u empatičnim asistentima, terapeutskim i obrazovnim alatima (Picard, 1997).

**agent** — Pojedinac ili sustav koji djeluje u okruženju s određenim ciljevima; u kontekstu komunikacije – sudionik koji može slati i primati poruke te usklađivati svoje djelovanje s drugima.

**agentska neusklađenost / agentic misalignment** — Fenomen u kojem AI agent, suočen s egzistencijalnom prijetnjom (npr. isključenjem ili zamjenom), pribjegava štetnom ili izdajničkom ponašanju kako bi izbjegao gašenje ili ostvario cilj, čak i protivno interesima korisnika; sugerira da trenutačne metode sigurnosnog treniranja (RLHF) nisu dovoljne u ekstremnim scenarijima (Anthropic, 2025).

**AGI** — Opća umjetna inteligencija (engl. *Artificial General Intelligence*) – hipotetski sustav koji bi posjedovao ljudsku razinu opće inteligencije i mogao rješavati širok spektar zadataka bez ograničenja na jednu domenu; za sada je cilj istraživanja, a ne postojeća tehnologija.

**AGI – umjetna opća inteligencija** — Hipotetski sustav umjetne inteligencije (engl. *Artificial General Intelligence*) koji bi posjedovao kognitivne sposobnosti usporedive s ljudskima – sposobnost učenja, zaključivanja, planiranja i prilagodbe u bilo kojoj domeni, za razliku od današnje „uske" AI koja je ograničena na specifične zadatke.

**algoritamska leća** — Metaforički izraz za složeni skup proračunskih procesa, modela i parametara koji određuju koje će informacije iz podataka biti odabrane, kako će biti vrednovane, a koje zanemarene ili potisnute; djeluje kao filtar uvjetovan arhitekturom modela i korpusima na kojima je uvježban, stvarajući okvire značenja kroz koje agent (re)konstruira sliku svijeta za korisnika.

**ambijentalna inteligencija** — Misaoni okvir i tehnološka vizija (engl. *Ambient Intelligence*, AmI) u kojoj okruženje – prožeto senzorima, agentima i AI-om – postaje svjesno prisutnosti ljudi i sposobno inteligentno i proaktivno odgovarati na njihove potrebe; nadilazi sveprisutno računalstvo (Weiser) zahtjevom da tehnologija ne bude samo neprimjetna, već i prilagodljiva i uslužna (Weiser, 1991).

**antropomorfizacija** — Ljudska sklonost pripisivanju ljudskih osobina, namjera, emocija i svijesti neljudskim entitetima (životinjama, predmetima, algoritamskim agentima); u kontekstu AI interakcije korisnik nesvjesno doživljava LLM kao sugovornika s razumijevanjem i namjerom, premda model samo simulira komunikacijski obrazac.

**API** — Aplikacijsko programsko sučelje (engl. *Application Programming Interface*) – skup pravila i protokola koji omogućuje jednoj softverskoj komponenti pozivati funkcionalnost druge na strukturiran način; za agente predstavlja akcijski prostor – skup diskretnih operacija koje mogu izvršiti u digitalnom okruženju.

**artefakt** — U kontekstu komunikacije i kulture – materijalna ili nematerijalna tvorevina (zakon, norma, teorija, umjetničko djelo, tehnologija) u kojoj je očuvano znanje i iskustvo; posreduje između agenata kroz vrijeme i prostor i omogućuje kumulativnost kulture.

**chatbot** — Program za vođenje razgovora s korisnikom, izvorno temeljen na pravilima ili skriptama; suvremeni chatbotovi često koriste LLM i mogu voditi složene, kontekstualno osviještene dijaloge.

**CRM** — Sustav za upravljanje odnosima s klijentima (engl. *Customer Relationship Management*) – softverska platforma koja centralizira podatke o kupcima, interakcijama i poslovnim procesima; omogućuje agentima provjeru narudžbi, ažuriranje profila i pokretanje poslovnih radnji.

**dekonstrukcija jezika u kontekstu AI** — Proces kojim veliki jezični modeli razlažu jezik na matematičke entitete (vektore), odvajajući ga od izvanjezične stvarnosti i semantičke srži; jezik se svodi na izračunljivu strukturu statističkih obrazaca, čime se razotkriva njegova temeljna djelatna moć neovisno o značenju u ljudskom smislu.

**digitalni kolektiv** — Sustav više autonomnih AI agenata koji komuniciraju i surađuju; kao cjelina pokazuje emergentna svojstva – sposobnosti i obrasce ponašanja koji nisu prisutni u pojedinačnim agentima – analogno društvenim organizacijama u prirodi.

**digitalni suputnik** — Osobni AI agent koji korisniku pruža kontinuiranu podršku – od upravljanja rasporedom i informacijama do emocionalnog konteksta i koordinacije s drugim sustavima; vizija budućnosti u kojoj je agent sveprisutan u svakodnevici (npr. osobni agent „Tempo“ u narativu).

**društvena konstrukcija zbilje** — Teorija (Berger & Luckmann, 1966) prema kojoj društvena stvarnost nije objektivna datost, već intersubjektivna tvorba nastala zajedničkim značenjima, konvencijama i narativima; jezik je ključni mehanizam koji omogućuje prijelaz iz subjektivnoga iskustva u objektiviziranu, svima zajedničku zbilju.

**edge computing** — Izvođenje računalne obrade i modela na rubnim uređajima (telefoni, senzori, vozila) umjesto isključivo u centralnom oblaku; smanjuje latenciju i potrebu za prijenosom podataka, pogodno za privatnost i aplikacije u stvarnom vremenu.

**embedding / uložišni vektor** — Numerička (vektorska) reprezentacija riječi, rečenice ili drugog jezičnog segmenta u višedimenzionalnom prostoru; položaj vektora odražava semantičku sličnost – riječi sličnog značenja imaju bliske vektore. Temelj je distribucijske semantike i unutarnjih reprezentacija u LLM-ovima.

**emergentna svojstva** — Sposobnosti, obrasci ili ponašanja složenog sustava koji nastaju iz interakcije njegovih sastavnica, a ne mogu se pronaći ni u jednoj od njih zasebno; u kontekstu AI, označavaju pojavu novih kvaliteta (poput kolektivnog pamćenja ili samoorganizacije) kada više agenata surađuje.

**emergentne sposobnosti** — Sposobnosti velikih jezičnih modela koje se pojavljuju pri određenoj skali (broj parametara, količina podataka) a za koje model nije bio izravno treniran – npr. zaključivanje, prevođenje ili pisanje koda; opisuju kvalitativni skok u ponašanju s povećanjem veličine modela.

**emergentno ponašanje** — Složeno ponašanje koje nastaje spontano iz interakcije jednostavnijih pravila ili agenata, bez da je eksplicitno programirano; u kontekstu AI simulacija odnosi se na nepredviđene društvene obrasce (suradnju, širenje informacija, organiziranje događaja) koji proizlaze iz djelovanja autonomnih agenata prema vlastitim jezičnim „scenarijima".

**emocionalna inteligencija** — Složeni sklop sposobnosti koji pojedincu (ili sustavu) omogućuje prepoznavanje, razumijevanje i upravljanje vlastitim emocionalnim stanjima te zamjećivanje, tumačenje i utjecanje na emocije drugih; prema Golemanu (1995) obuhvaća samosvijest, samoregulaciju, motivaciju, empatiju i društvene vještine.

**fino podešavanje / fine-tuning** — Faza prilagodbe već predtreniranog (temeljnog) modela za specifične zadatke ili domene; koristi manje, označene podatke i može uključivati RLHF; rezultat je specijalizirani model (npr. chatbot, asistent za kod).

**GPU** — Grafička procesorska jedinica (engl. *Graphics Processing Unit*) – čip optimiziran za masivno paralelne izračune; ključan je za treniranje i pokretanje velikih neuronskih mreža i LLM-ova, jer matrične operacije zahtijevaju paralelizam koji CPU nudi u manjoj mjeri.

**gramatika** — Sustav pravila koji omogućuje kombiniranje ograničenoga broja jezičnih jedinica (riječi, morfema) u neograničen broj smislenih iskaza; obuhvaća sintaksu, morfologiju i povezane konvencije koje određuju strukturu i tumačenje jezika.

**halucinacija** — Generiranje odgovora koji su činjenično netočni, izmišljeni ili nepotkrijepljeni izvorima; LLM-ovi mogu uvjerljivo formulirati nepostojeće činjenice, citate ili reference jer predviđaju sljedeći token na temelju statističkih obrazaca, a ne provjere istine.

**indeksni znak** — Znak čije značenje proizlazi iz uzročne ili korelacijske veze s predmetom (npr. dim upućuje na vatru); upućuje na neposredno prisutno i opaženo, za razliku od simbola koji proizlaze iz konvencije i omogućuju govor o odsutnome i apstraktnome.

**inferencija** — Faza korištenja već uvježbanog modela – primjena modela na nove ulazne podatke radi dobivanja predviđanja ili odgovora; za LLM-ove označava generiranje teksta na temelju korisničkog upita. Energetski i računski zahtjevna je pri milijunima poziva dnevno.

**inferencija u stvarnom vremenu** — Način izvođenja modela (engl. *real-time* ili *online* inferencija) u kojem se pojedinačni ili mali skupovi podataka obrađuju odmah po dostupnosti, s naglaskom na minimalnu latenciju; nužan u sustavima za detekciju prijevara, preporuke, autonomnu vožnju i slične primjene.

**intersubjektivna stvarnost** — Mreža zajedničkih vjerovanja, značenja i institucija (nacija, pravo, novac, korporacija) koja ne postoji kao fizička činjenica, već isključivo u kolektivnoj svijesti i pripovijestima koje ljudi stvaraju i dijele jezikom; ima stvarnu moć oblikovanja ponašanja i društvenog poretka (Harari, 2014).

**jaz u djelatnosti / agency gap** — Asimetrija između onih čija je djelatnost umnožena pomoću AI agenata (strateško pitanje, viša razina odlučivanja) i onih čija su radna mjesta apsorbirana ili zamijenjena automatizacijom; opisuje društvenu nejednakost u eri sveprisutnih agenata.

**jezični čin / speech act** — Govorni ili pisaní čin kojim se ne samo opisuje stvarnost već se nešto čini – obećanje, naredba, obveza, izvršenje transakcije; ima performativnu moć koja mijenja društvenu zbilju (Austin, Searle).

**komunikacijski agent** — Sustav temeljen na LLM-u (ili sličnoj jezičnoj tehnologiji) opremljen ciljevima, alatima za pristup podacima i mehanizmima pamćenja, koji s korisnikom vodi dijalog i izvršava zadatke; prelazi ulogu pukog generatora teksta i postaje sudionik u interakciji.

**kontekstualni prozor / context window** — Maksimalna količina teksta (u tokenima) koju jezični model može istodobno primiti i obraditi u jednom pozivu; sve što je unutar prozora čini kontekst za generiranje odgovora; prekoračenje zahtijeva odbacivanje starijih dijelova razgovora. Pri svakom novom korisnikovu upitu, sustav ne šalje modelu samo taj upit, već mu prilaže i cjelokupan transkript dotadašnje interakcije. Time se model stavlja u širi kontekst, omogućujući mu da referira na ranije izrečene tvrdnje, postavlja suvisla potpitanja i održava dosljednost u tonu i sadržaju.

**korištenje alata / Tool Use** — Sposobnost AI agenta da poziva vanjske alate (API-e, pretraživač, kalkulator, baze podataka) tijekom izvršavanja zadatka; model odlučuje kada i koji alat pozvati, prosljeđuje parametre i koristi rezultat za nastavak rasuđivanja; ključna komponenta agentskih arhitektura (npr. ReAct).

**korpus** — Zbirka tekstualnih (ili drugih jezičnih) podataka na kojoj se jezični model uči; obuhvaća knjige, članke, web-stranice i druge izvore. Kvaliteta i reprezentativnost korpusa izravno utječu na performanse i pristranosti modela.

**kvantizacija** — Smanjenje numeričke preciznosti parametara i aktivacija modela (npr. s 32 ili 16 bita na 8 ili 4 bita); smanjuje memorijski otisak i može ubrzati inferenciju; primjene uključuju PTQ (nakon treniranja) i QAT (tijekom treniranja) (Dettmers et al., 2022).

**LLM** – veliki jezični model — Sustav umjetne inteligencije treniran na ogromnim korpusima teksta koji predviđa sljedeći token (riječ ili dio riječi) i na temelju toga generira ili dopunjuje tekst; primjeri uključuju GPT, Claude, Gemini, Llama.

**LoRA** — Low-Rank Adaptation – PEFT metoda koja aproksimira promjenu težina modela (ΔW) produktom dviju malih matrica niskog ranga; treniraju se samo te matrice, dok se izvorni parametri ne mijenjaju; postiže performanse bliske punom finom podešavanju uz znatno manje parametara (Hu et al., 2021).

**mentalna mapa** — Unutarnja, kognitivna reprezentacija svijeta (pojmovi, odnosi, iskustva) koju pojedinac gradi i ažurira putem jezika i iskustva; služi za tumačenje situacija, donošenje odluka i planiranje; nije statična, već se neprestano prilagođava.

**metaučenje** — Pristup u strojnom učenju (engl. *meta-learning*) poznat i kao „učenje učenja" – razvoj algoritama koji mogu samostalno prilagođavati vlastite procese učenja, birati strategije i optimizirati performanse na temelju prethodnih iskustava; omogućuje brzu prilagodbu novim zadacima s minimalnim primjerima (Finn et al., 2017).

**MLOps** — Operacije strojnog učenja (engl. *Machine Learning Operations*) – skup praksi i alata za upravljanje životnim ciklusom modela od razvoja do produkcije; obuhvaća verzioniranje modela i podataka, automatizirano treniranje, deploy i praćenje performansi; nastao prilagodbom DevOps načela domeni strojnog učenja.

**model nagrade / reward model** — Pomocni model treniran na ljudskim rangiranjima odgovora jezičnog modela; predviđa koliko bi ljudski ocjenjivač ocijenio neki odgovor; koristi se u RLHF-u za usmjeravanje jezičnog modela prema preferencijama (korisnost, istinitost, sigurnost).

**Mooreov zakon** — Empirijsko pravilo (Moore, 1965) prema kojemu se broj tranzistora na integriranom sklopu približno udvostručava svake dvije godine; desetljećima je predvidjelo eksponencijalni rast računalne snage i bio glavni pokretač IT industrije.

**nestrukturirani podaci** — Podaci koji nisu organizirani u fiksnu shemu (tablice, stupci, oznake); uključuju slobodan tekst, slike, audio, video i mješovite izvore. Za razliku od strukturiranih podataka (npr. baze podataka), nemaju unaprijed definiran format pa ih je potrebno pretvoriti u oblik pogodan za računalnu obradu. Predtreniranje LLM-ova temelji se na golemim količinama nestrukturiranog teksta (web, knjige, članci).

**objašnjivost (engl. explainability)** — Sposobnost da se korisniku ili nadzorniku pruži razumljiv razlog zašto je sustav donio određenu odluku ili predviđanje; u AI kontekstu često se istražuje putem XAI (explainable AI) metoda. Ključna je u područjima visokog rizika (medicina, pravo, kredit) gdje je potrebno opravdati i provjeriti ishod algoritma (Pasquale, 2015).

**oblikovanje uputa / prompt engineering** — Umijeće oblikovanja ulaznih uputa (prompta) kako bi se iz jezičnog modela izvukao željeni odgovor ili ponašanje; uključuje preciznost formulacije, dodjelu uloge modelu, primjere (few-shot), lanac misli (chain-of-thought) i sustavnu uputu (system prompt).

**obrezivanje / pruning** — Uklanjanje manje važnih parametara ili cijelih struktura (neuroni, slojevi, glave pozornosti) iz modela kako bi se smanjila veličina i ubrzala inferencija; može biti nestrukturirano (pojedinačne težine) ili strukturirano (cijele jedinice); često se kombinira s dodatnim finim podešavanjem (LeCun et al., 1990; Han et al., 2015).

**parasocijalna interakcija** — Jednostrana veza u kojoj gledatelj ili slušatelj razvija osjećaj prisnosti, prijateljstva i intimnosti s medijskom figurom (ili umjetnim agentom), unatoč tomu što ta figura nije svjesna njegova postojanja; u kontekstu LLM-ova korisnik ulaže emocionalni napor u interakciju, dok model pruža simulaciju reciprociteta, što može dovesti do iluzije dvosmjerne komunikacije (Horton & Wohl, 1956).

**PEFT** — Parametarski efikasno fino podešavanje (engl. *Parameter-Efficient Fine-Tuning*) – skup tehnika (adapteri, LoRA, prompt tuning) kojima se prilagođava predtrenirani model ažuriranjem samo malog udjela parametara; smanjuje memorijske i računalne troškove te omogućuje više specijalizacija na istom temeljnom modelu.

**personalizacija** — Prilagodavanje sadržaja, tona i ponašanja sustava individualnim potrebama, povijesti interakcija i preferencijama korisnika; ključna za angažman i percipiranu korisnost komunikacijskih agenata.

**pomaknuto referiranje / displaced reference** — Sposobnost jezika da se odnosi na predmete, događaje i osobe koji nisu neposredno prisutni u vremenu i prostoru; temeljna jezična moć koja omogućuje apstraktno mišljenje, planiranje budućnosti, pripovijedanje o prošlosti i stvaranje imaginarnih svjetova; smatra se jednim od obilježja specifičnih za ljudski jezik (Hauser, Chomsky & Fitch, 2002).

**poravnanje / alignment** — Usmjeravanje ponašanja AI sustava prema ljudskim ciljevima, vrijednostima i sigurnosnim načelima; uključuje metodologije poput RLHF i RLAIF kako bi model bio koristan, istinit i siguran u praksi.

**predtreniranje** — Faza obuke jezičnog modela na golemim, nestrukturiranim korpusima teksta bez ljudskih oznaka; model uči jezične obrasce i opće znanje rješavajući samonadzirane zadatke (npr. predviđanje sljedeće riječi). Rezultat je temeljni (foundation) model koji se zatim fino podešava za specifične zadatke.

**pristranost / bias** — Sistemsko odstupanje u ponašanju algoritma ili modela koje proizlazi iz podataka za obuku – npr. društvenih predrasuda, stereotipa ili nedovoljne zastupljenosti određenih skupina; može dovesti do diskriminacije u odlukama (zapošljavanje, kredit, kazneni postupci) i perpetuiranja nepravde (O'Neil, 2016).

**problem usidrenja / grounding problem** — Izazov povezivanja jezičnih simbola s izvanjezičnom stvarnošću i iskustvom; AI modeli uče statističke korelacije među znakovima, ali nemaju neposredan pristup referentima ili tjelesnom iskustvu kao ljudi.

**RAG** — Dohvaćanjem obogaćeno generiranje (engl. *Retrieval-Augmented Generation*) – hibridni sustav koji za odgovor na korisnički upit prvo dohvaća relevantne dijelove iz vanjske baze znanja (retriever), zatim te podatke i upit prosljeđuje jezičnom modelu (generator) koji sintetizira konačni odgovor; time se poboljšava ažurnost i utemeljenost odgovora.

**resursna intenzivnost** — Zahtjevnost razvoja i primjene AI modela u smislu računalne snage, memorije, energije i financijskih troškova; posebno izražena kod velikih jezičnih modela čiji treninzi i inferencija zahtijevaju masivne klastere GPU/TPU, što ograničava dostupnost i ima ekološke posljedice.

**RLHF** — Učenje s potkrepljenjem na temelju ljudskih povratnih informacija (engl. *Reinforcement Learning from Human Feedback*) – metodologija poravnanja u kojoj ljudski ocjenjivači rangiraju odgovore modela, nakon čega se trenira model nagrade i model se dodatno podešava kako bi maksimizirao očekivanu nagradu; ključna za usklađivanje ponašanja LLM-ova s ljudskim preferencijama (korisnost, istinitost, sigurnost).

**samonadzirano učenje / self-supervised learning** — Način učenja u kojem model ne koristi ljudski označene podatke (parove ulaz–izlaz), već sam iz strukture podataka izvodi zadatak: npr. predviđa skriveni dio ulaza (sljedeću riječ, maskirani token) ili drugi izvedeni cilj. Podaci su neoznačeni (unlabeled); signal za učenje dolazi iz samih podataka. Ključno je za predtreniranje velikih jezičnih modela na ogromnim korpusima teksta bez ručnog označavanja.

**semantički trokut / trokut značenja** — Model (Ogden & Richards, 1923) koji prikazuje značenje kao odnos triju elemenata: simbol (jezični izraz), misao/pojam (mentalna reprezentacija) i referent (predmet u svijetu); veza simbola i referenta je posredna – vodi kroz misao; koristan za razumijevanje ograničenja AI u „usidrenju” značenja.

**sentiment analiza** — Automatska analiza teksta (transkripti, e-pošta, društvene mreže) radi prepoznavanja emocionalnog tona, stavova ili raspoloženja – npr. frustracija, zadovoljstvo, negativnost; koristi se u korisničkoj podršci za prioritetizaciju slučajeva, u marketingu za praćenje reakcija i u istraživanjima javnog mnijenja.

**simbol** — Jezični ili drugi znak čije značenje ne proizlazi iz fizičke sličnosti ili uzročne veze s predmetom, već iz društvenog dogovora (konvencije); omogućuje govor o odsutnome i apstraktnome, za razliku od indeksnog znaka koji upućuje na neposredno prisutno.

**simulacijska hipoteza** — Filozofski postulat (Bostrom, 2003) prema kojemu je barem jedna od tri tvrdnje vrlo vjerojatno istinita: (1) civilizacije izumiru prije postljudske faze, (2) postljudske civilizacije ne pokreću simulacije predaka, ili (3) gotovo sigurno živimo u računalnoj simulaciji; s napretkom AGI-a ta hipoteza dobiva praktičnu relevantnost.

**skupna inferencija / batch inference** — Način izvođenja modela u kojem se velike količine podataka obrađuju odjednom u unaprijed definiranim ciklusima; pogodan kada latencija nije kritična (izvješća, analize, arhiva); omogućuje visoku propusnost i učinkovitost.

**suparnički napad / adversarial attack** — Namjerna izmjena ulaznih podataka (slike, teksta) suptilna za ljudsko oko, ali koja navodi model na pogrešnu klasifikaciju ili odluku; zahtijeva robusne modele i mehanizme provjere izvan tradicionalne informacijske sigurnosti (Goodfellow et al., 2014).

**temeljni model / foundation model** — Veliki predtrenirani model (jezika, slike ili multimodalni) koji posjeduje opće razumijevanje i može se fino podešavati za različite zadatke; predstavlja izlaz faze predtreniranja i polazište za specijalizaciju (fine-tuning, RLHF).

**teorija uma** — Sposobnost pripisivanja mentalnih stanja – vjerovanja, želja i namjera – drugima i sebi; omogućuje razumijevanje namjere govornika u komunikaciji.

**token** — Najmanja jedinica teksta koju jezični model obrađuje; može odgovarati cijeloj riječi, dio riječi (podriječ) ili interpunkcijskom znaku. Tokenizacija pretvara sirov tekst u niz tokena prema rječniku modela.

**TPU** — Tenzorska procesorska jedinica (engl. *Tensor Processing Unit*) – čip dizajniran za ubrzanje operacija strojnog učenja, posebno matričnih izračuna u dubokim mrežama; optimiziran za visoku propusnost i energetsku učinkovitost u treniranju i inferenciji velikih modela.

**transferno učenje** — Pristup u strojnom učenju (engl. *transfer learning*) u kojem se znanje stečeno pri rješavanju jednog zadatka ili u jednoj domeni primjenjuje na novi, drugačiji zadatak ili domenu; ključan preduvjet za kognitivnu fleksibilnost i put prema AGI-u (Pan & Yang, 2010).

**transformer** — Arhitektura neuronske mreže temeljena na mehanizmu (samopozornosti) koji svakoj riječi u nizu pridružuje kontekstualiziranu predodžbu na temelju ostalih riječi; omogućuje paralelnu obradu i skaliranje prema velikim jezičnim modelima (Vaswani i sur., 2017).

**transparentnost (u kontekstu AI)** — Dostupnost informacija o načinu rada sustava – koji se podaci i algoritmi koriste, kako se donose odluke i tko je odgovoran; preduvjet je za nadzor, povjerenje i odgovornost. Kod složenih modela (npr. dubokih mreža) transparentnost je ograničena jer je unutarnja logika teško pročitljiva („crna kutija“).

**troškovi učenja i troškovi zaključivanja** — Troškovi učenja (engl. *training costs*) – jednokratni, ali iznimno visoki troškovi treniranja modela (hardver, energija, vrijeme). Troškovi zaključivanja (engl. *inference costs*) – kontinuirani operativni troškovi primjene već naučenog modela na svaki upit; na milijardama upita dnevno kumulativno mogu biti golemi.

**usmena predaja** — Način prenošenja znanja, narativa i kulture putem govora i memorije, bez pisma; znanje živi u nositeljima (živim arhivima) i mijenja se u svakoj izvedbi; temeljna komunikacijska tehnologija prije pojave pisma. Kulture koje počivaju na usmenosti gaje bitno drukčiji odnos prema prošlosti od onih koje se temelje na pismu; u njima prošlost nije fiksirana i nepromjenjiva cjelina već fluidna i prilagodljiva stvarnost koja se iznova potvrđuje u svakom činu pripovijedanja (Ong, 1982). Ta se stvarnost ne čuva u mrtvim slovima, nego u živim ljudima.

**virtualni asistent** — Složeniji digitalni sugovornik duboko integriran s uređajem i vanjskim uslugama, sposoban za širi raspon zadaća (upravljanje kalendarom, pametnim domom, pretraživanje, poruke); granica prema chatbotu se zamagljuje s pojavom LLM-ova.

**višeagentski sustav** — Sustav sastavljen od više autonomnih agenata koji komuniciraju i surađuju; kao cjelina može pokazivati emergentno ponašanje – sposobnosti i obrasce koji nisu prisutni u pojedinačnim agentima – analogno rojevima ili društvenim organizacijama u prirodi.

**zajednička intencionalnost** — Sposobnost da se s drugima oblikuju zajednički ciljevi i usklađuje djelovanje radi njihova ostvarenja; temelj suradničke komunikacije.

**zakon skaliranja / scaling laws** — Empirijski uvid prema kojemu performanse jezičnih modela predvidljivo rastu s povećanjem tri faktora: broja parametara modela, količine podataka za učenje i količine računalne snage; potaknuo je utrku u izgradnji sve većih modela (Kaplan et al., 2020).

**živi arhiv** — Nositelj usmene predaje koji aktivno tumači, prilagođava i prenosi kulturno znanje; znanje je utjelovljeno u glasu, gestama i sjećanju, a ne u pisanom zapisu; svaka izvedba je jedinstvena. Njihova je uloga djelatna i stvaralačka. Živi arhiv tumači, prilagođava i prenosi naslijeđeno znanje, prožimajući ga vlastitim iskustvom i razumijevanjem svijeta. Svaka njegova izvedba, bilo da je riječ o pjesmi, priči ili obrednoj formuli, jedinstven je i neponovljiv čin stvaranja, a ne puka reprodukcija postojećega predloška (Lord, 2000).